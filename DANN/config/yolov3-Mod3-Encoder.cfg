[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

#001
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample
#002
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

#003
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

#004
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#005
[shortcut]
from=-3
activation=linear

# Downsample
#006
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

#007
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#008
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#009
[shortcut]
from=-3
activation=linear

#010
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#011
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#012
[shortcut]
from=-3
activation=linear

# Downsample
#013
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

#014
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#015
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#016
[shortcut]
from=-3
activation=linear

#017
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#018
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#019
[shortcut]
from=-3
activation=linear

#020
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#021
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#022
[shortcut]
from=-3
activation=linear

#023
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#024
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#025
[shortcut]
from=-3
activation=linear

#026
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#027
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#028
[shortcut]
from=-3
activation=linear

#029
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#030
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#031
[shortcut]
from=-3
activation=linear

#032
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#033
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#034
[shortcut]
from=-3
activation=linear

#035
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#036
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#037
[shortcut]
from=-3
activation=linear

# Downsample
#038
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

#039
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#040
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#041
[shortcut]
from=-3
activation=linear

#042
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#043
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#044
[shortcut]
from=-3
activation=linear

#045
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#046
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#047
[shortcut]
from=-3
activation=linear

#048
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#049
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#050
[shortcut]
from=-3
activation=linear

#051
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#052
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#053
[shortcut]
from=-3
activation=linear

#054
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#055
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#056
[shortcut]
from=-3
activation=linear

#057
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#058
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#059
[shortcut]
from=-3
activation=linear

#060
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#061
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#062
[shortcut]
from=-3
activation=linear

# Downsample
#063
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

#064
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#065
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

#066
[shortcut]
from=-3
activation=linear

#067
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#068
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

#069
[shortcut]
from=-3
activation=linear

#070
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#071
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

#072
[shortcut]
from=-3
activation=linear

#073
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#074
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

#075
[shortcut]
from=-3
activation=linear

######################
#076
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#077
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

#078
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#079
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

#080
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky


#085 (81)
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#086 (82)
[upsample]
stride=2

#087 (83)
[route]
layers = -1, 61

################
#088 (84)
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#089 (85)
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

#090 (86)
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#091 (87)
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

#092 (88)
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
################
#097 (89)
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#098 (90)
[upsample]
stride=2

#099 (91)
[route]
layers = -1, 36

####################
#100 (92)
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#101 (93)
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

#102 (94)
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#103 (95)
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

#104 (96)
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
